#! /bin/bash

# start everything that's need to run kafka.

docker run -d \
    --net=host \
    --name=zookeeper \
    -e ZOOKEEPER_CLIENT_PORT=2181 \
    confluentinc/cp-zookeeper:latest

docker run -d \
    --net=host \
    --name=kafka \
    -e KAFKA_ZOOKEEPER_CONNECT=localhost:2181 \
    -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
    confluentinc/cp-kafka:latest

docker run -d \
  --net=host \
  --name=schema-registry \
  -e SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=localhost:2181 \
  -e SCHEMA_REGISTRY_HOST_NAME=localhost \
  -e SCHEMA_REGISTRY_LISTENERS=http://localhost:8081 \
  confluentinc/cp-schema-registry:latest

docker run -d \
  --net=host \
  --name=kafka-rest \
  -e KAFKA_REST_ZOOKEEPER_CONNECT=localhost:2181 \
  -e KAFKA_REST_LISTENERS=http://localhost:8082 \
  -e KAFKA_REST_SCHEMA_REGISTRY_URL=http://localhost:8081 \
  -e KAFKA_REST_HOST_NAME=localhost \
  confluentinc/cp-kafka-rest:latest

## Optionally, create these ahead of time
docker run \
 --net=host \
 --rm \
 confluentinc/cp-kafka:latest \
 kafka-topics --create --topic example-offsets --partitions 1 --replication-factor 1 --if-not-exists --zookeeper localhost:2181

docker run \
 --net=host \
 --rm \
 confluentinc/cp-kafka:latest \
 kafka-topics --create --topic example-config --partitions 1 --replication-factor 1 --if-not-exists --zookeeper localhost:2181

docker run \
 --net=host \
 --rm \
 confluentinc/cp-kafka:latest \
 kafka-topics --create --topic example-status --partitions 1 --replication-factor 1 --if-not-exists --zookeeper localhost:2181


 docker run \
   --net=host \
   --rm \
   confluentinc/cp-kafka \
   kafka-topics --describe --zookeeper localhost:2181

docker run -d \
  --name=kafka-connect \
  --net=host \
  -e CONNECT_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor \
  -e CONNECT_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor \
  -e CONNECT_BOOTSTRAP_SERVERS=localhost:9092 \
  -e CONNECT_REST_PORT=8083 \
  -e CONNECT_GROUP_ID="example" \
  -e CONNECT_CONFIG_STORAGE_TOPIC="example-config" \
  -e CONNECT_OFFSET_STORAGE_TOPIC="example-offsets" \
  -e CONNECT_STATUS_STORAGE_TOPIC="example-status" \
  -e CONNECT_KEY_CONVERTER="org.apache.kafka.connect.storage.StringConverter" \
  -e CONNECT_VALUE_CONVERTER="io.confluent.connect.avro.AvroConverter" \
  -e CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL="http://localhost:8081" \
  -e CONNECT_INTERNAL_KEY_CONVERTER="org.apache.kafka.connect.json.JsonConverter" \
  -e CONNECT_INTERNAL_VALUE_CONVERTER="org.apache.kafka.connect.json.JsonConverter" \
  -e CONNECT_REST_ADVERTISED_HOST_NAME="localhost" \
  -e CONNECT_LOG4J_ROOT_LOGLEVEL=DEBUG \
  confluentinc/cp-kafka-connect:latest

# postgres
docker run -d \
	--name=kafka-postgres \
	-p 7999:5432 \
	-e POSTGRES_USER=postgres \
	-e POSTGRES_DB=kafka \
	mdillon/postgis

## create topics
##
## We shall create topics beforehand; otherwise, it seems, kafka tries to 
## create the topics itself, but sometimes it tries to assign
## a topic to a broker.id that already belongs to one of the topics
## it just created.
##
sleep 4 # in seconds
./create-topics
./create-connector.sh 